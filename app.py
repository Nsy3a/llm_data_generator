import streamlit as st
import os
import json
import pandas as pd
import time
from dotenv import load_dotenv
from openai import OpenAI
import anthropic
import google.generativeai as genai

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ================== åç«¯é€»è¾‘ï¼šå¤šæ¨¡å‹é€‚é…å™¨ ==================

class PollinationsAIClient:
    """Pollinations AI å®¢æˆ·ç«¯ - æ”¯æŒæ–‡æœ¬å’Œå›¾åƒç”Ÿæˆ"""
    def __init__(self, model_name="openai", model_type="text"):
        self.base_url = "https://text.pollinations.ai" if model_type == "text" else "https://image.pollinations.ai"
        self.model_name = model_name
        self.model_type = model_type
    
    def generate_text(self, prompt, system_prompt=None, **kwargs):
        """ç”Ÿæˆæ–‡æœ¬ - ä½¿ç”¨Pollinations AIæ–‡æœ¬API"""
        import requests
        import urllib.parse
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        full_prompt = prompt
        if system_prompt:
            full_prompt = f"{system_prompt}\n\nç”¨æˆ·ä»»åŠ¡ï¼š{prompt}"
        
        # URLç¼–ç æç¤ºè¯
        encoded_prompt = urllib.parse.quote(full_prompt)
        
        # æ„å»ºè¯·æ±‚URL
        url = f"{self.base_url}/prompt/{encoded_prompt}"
        
        # æ·»åŠ å‚æ•°
        params = {"model": self.model_name}
        if kwargs.get("seed"):
            params["seed"] = kwargs["seed"]
        if kwargs.get("private"):
            params["private"] = "true"
        
        try:
            response = requests.get(url, params=params, timeout=60)
            response.raise_for_status()
            return response.text
        except Exception as e:
            return f"Error: {str(e)}"
    
    def generate_image(self, prompt, **kwargs):
        """ç”Ÿæˆå›¾åƒ - ä½¿ç”¨Pollinations AIå›¾åƒAPI"""
        import requests
        import urllib.parse
        
        # URLç¼–ç æç¤ºè¯
        encoded_prompt = urllib.parse.quote(prompt)
        
        # æ„å»ºè¯·æ±‚URL
        url = f"{self.base_url}/prompt/{encoded_prompt}"
        
        # æ·»åŠ å‚æ•°
        params = {
            "model": kwargs.get("model", "flux"),
            "width": kwargs.get("width", 1024),
            "height": kwargs.get("height", 1024),
            "seed": kwargs.get("seed"),
            "nologo": "true" if kwargs.get("nologo", False) else "false",
            "private": "true" if kwargs.get("private", True) else "false",
            "enhance": "true" if kwargs.get("enhance", False) else "false"
        }
        
        # ç§»é™¤Noneå€¼
        params = {k: v for k, v in params.items() if v is not None}
        
        try:
            response = requests.get(url, params=params, timeout=300)
            response.raise_for_status()
            return response.content  # è¿”å›å›¾åƒäºŒè¿›åˆ¶æ•°æ®
        except Exception as e:
            return f"Error: {str(e)}"

class LLMClient:
    def __init__(self, provider, api_key, base_url=None, model_name=None):
        self.provider = provider
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name

    def generate(self, system_prompt, user_prompt):
        """ç»Ÿä¸€çš„ç”Ÿæˆæ¥å£ï¼Œå±è”½ä¸åŒå‚å•† SDK çš„å·®å¼‚"""
        try:
            if self.provider == "OpenAI":
                client = OpenAI(api_key=self.api_key, base_url=self.base_url)
                response = client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    response_format={"type": "json_object"} # å°è¯•å¼ºåˆ¶JSONæ¨¡å¼
                )
                return response.choices[0].message.content

            elif self.provider == "Custom":
                if not self.base_url or not self.model_name:
                    return f"Error: Custom provider requires both base_url and model_name to be configured"
                client = OpenAI(api_key=self.api_key, base_url=self.base_url)
                response = client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    response_format={"type": "json_object"} # å°è¯•å¼ºåˆ¶JSONæ¨¡å¼
                )
                return response.choices[0].message.content

            elif self.provider == "Anthropic":
                client = anthropic.Anthropic(api_key=self.api_key)
                message = client.messages.create(
                    model=self.model_name,
                    max_tokens=4096,
                    temperature=0.7,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_prompt}]
                )
                return message.content[0].text

            elif self.provider == "Google":
                genai.configure(api_key=self.api_key)
                model = genai.GenerativeModel(
                    self.model_name,
                    generation_config={"response_mime_type": "application/json"}
                )
                # Gemini system prompt éœ€è¦åœ¨å®ä¾‹åŒ–æ—¶é…ç½®æˆ–æ‹¼æ¥åˆ° user promptï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
                full_prompt = f"System Instruction:\n{system_prompt}\n\nUser Task:\n{user_prompt}"
                response = model.generate_content(full_prompt)
                return response.text

            elif self.provider == "Pollinations":
                # ä½¿ç”¨Pollinations AIç”Ÿæˆæ–‡æœ¬
                client = PollinationsAIClient(model_name=self.model_name, model_type="text")
                # æ„å»ºé¢å¤–å‚æ•°
                kwargs = {}
                if hasattr(self, 'seed') and self.seed:
                    kwargs['seed'] = self.seed
                if hasattr(self, 'private') and self.private:
                    kwargs['private'] = self.private
                return client.generate_text(user_prompt, system_prompt, **kwargs)

        except Exception as e:
            return f"Error: {str(e)}"

def clean_json_text(text):
    """æ¸…æ´— JSON å­—ç¬¦ä¸²ï¼Œç§»é™¤ Markdown æ ‡è®°"""
    import re
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*$', '', text)
    return text.strip()

# ================== å‰ç«¯ç•Œé¢ (Streamlit) ==================

st.set_page_config(page_title="AI æ•°æ®é›†è’¸é¦å·¥å‚", layout="wide", page_icon="ğŸ­")

st.title("ğŸ­ é«˜è´¨é‡æ•°æ®é›†è’¸é¦å·¥å‚")
st.markdown("åˆ©ç”¨å¼ºå¤§çš„å¤§æ¨¡å‹ï¼ˆTeacher Modelï¼‰ç”Ÿæˆç”¨äºå¾®è°ƒï¼ˆSFTï¼‰çš„é«˜è´¨é‡æŒ‡ä»¤æ•°æ®é›†ã€‚")

# --- ä¾§è¾¹æ ï¼šæ¨¡å‹é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹è®¾ç½®")
    
    provider = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æœåŠ¡å•†",
        ["OpenAI", "Anthropic", "Google", "Pollinations", "Custom"]
    )

    api_key = ""
    base_url = None
    model_name = ""

    # åŠ¨æ€æ˜¾ç¤ºé…ç½®é¡¹ï¼Œä¼˜å…ˆè¯»å– .env
    if provider == "OpenAI":
        api_key = st.text_input("API Key", value=os.getenv("OPENAI_API_KEY", ""), type="password", placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxx")
        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"])
    
    elif provider == "Anthropic":
        api_key = st.text_input("API Key", value=os.getenv("ANTHROPIC_API_KEY", ""), type="password", placeholder="sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx")
        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["claude-3-5-sonnet-20240620", "claude-3-opus-20240229"])
        
    elif provider == "Google":
        api_key = st.text_input("API Key", value=os.getenv("GOOGLE_API_KEY", ""), type="password", placeholder="AIxxxxxxxxxxxxxxxxxxxxxxxx")
        model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gemini-1.5-pro", "gemini-1.5-flash"])
        
    elif provider == "Pollinations":
        st.info("ğŸŒ¸ Pollinations AI - å…è´¹æ— éœ€æ³¨å†Œçš„AIç”Ÿæˆå¹³å°")
        api_key = "pollinations"  # Pollinations AIä¸éœ€è¦APIå¯†é’¥
        
        # æ–‡æœ¬æ¨¡å‹é€‰æ‹©
        text_models = ["openai", "mistral", "mistral-large", "claude", "gemini", 
                      "llama", "llamaguard", "command", "searchgpt", "unity"]
        model_name = st.selectbox("é€‰æ‹©æ–‡æœ¬æ¨¡å‹", text_models, help="é€‰æ‹©ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„æ¨¡å‹")
        
        # é«˜çº§å‚æ•°é…ç½®
        with st.expander("ğŸ”§ é«˜çº§å‚æ•°é…ç½®"):
            st.write("**æ–‡æœ¬ç”Ÿæˆå‚æ•°**:")
            pollinations_seed = st.number_input("éšæœºç§å­ (æ–‡æœ¬)", min_value=0, max_value=999999, value=0, help="0è¡¨ç¤ºéšæœº")
            pollinations_private = st.checkbox("ç§æœ‰æ¨¡å¼", value=True, help="ç”Ÿæˆçš„å†…å®¹ä¸æ˜¾ç¤ºåœ¨å…¬å…±æµä¸­")
        
    elif provider == "Custom":
        st.info("é€‚ç”¨äº DeepSeek, Groq, Moonshot æˆ– æœ¬åœ° vLLM/Ollama")
        base_url = st.text_input("Base URL", value=os.getenv("CUSTOM_BASE_URL", ""), placeholder="https://api.example.com/v1")
        api_key = st.text_input("API Key", value=os.getenv("CUSTOM_API_KEY", ""), type="password", placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxx")
        model_name = st.text_input("Model Name", value="", placeholder="llama3-70b, deepseek-chat, gpt-4")

    if not api_key and provider != "Pollinations":
        st.warning("âš ï¸ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®å¯†é’¥æˆ–åœ¨ä¸Šæ–¹è¾“å…¥")

# --- ä¸»ç•Œé¢é€»è¾‘ ---

# åˆå§‹åŒ– Session State (ç”¨äºä¿å­˜ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ•°æ®)
if "topics" not in st.session_state:
    st.session_state.topics = []
if "generated_data" not in st.session_state:
    st.session_state.generated_data = []

# åŒºåŸŸ 1: é¢†åŸŸå®šä¹‰
st.subheader("1. å®šä¹‰ç›®æ ‡é¢†åŸŸä¸ä»»åŠ¡")
col1, col2 = st.columns([3, 1])
with col1:
    target_domain = st.text_input("è¯·è¾“å…¥ä½ æƒ³å¤åˆ»çš„é¢†åŸŸèƒ½åŠ›", placeholder="ä¾‹å¦‚ï¼šPythonå®‰å…¨ä»£ç å®¡è®¡ã€åŒ»ç–—é—®è¯Šå¯¹è¯ã€åˆä¸­æ•°å­¦å‡ ä½•æ¨ç†")
with col2:
    num_topics = st.number_input("ç”Ÿæˆä¸»é¢˜æ•°é‡", min_value=1, max_value=50, value=5)

if st.button("ğŸš€ ç”Ÿæˆä»»åŠ¡åˆ†ç±»æ ‘ (Taxonomy)"):
    if not api_key and provider != "Pollinations":
        st.error("è¯·å…ˆé…ç½® API Key")
    else:
        client = LLMClient(provider, api_key, base_url, model_name)
        # ä¼ é€’Pollinations AIçš„é«˜çº§å‚æ•°
        if provider == "Pollinations":
            client.seed = pollinations_seed if pollinations_seed > 0 else None
            client = LLMClient(provider, api_key, base_url, model_name)
        # ä¼ é€’Pollinations AIçš„é«˜çº§å‚æ•°
        if provider == "Pollinations":
            client.seed = pollinations_seed if pollinations_seed > 0 else None
            client.private = pollinations_private
        
        with st.spinner(f"æ­£åœ¨è®© {model_name} åˆ†æé¢†åŸŸçŸ¥è¯†..."):
            system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“å®¶çº§æ•°æ®æ¶æ„å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é¢†åŸŸï¼Œæ‹†è§£å‡ºå…·ä½“çš„ç»†åˆ†ä»»åŠ¡åœºæ™¯ã€‚"
            user_prompt = f"""
            é¢†åŸŸï¼š{target_domain}
            è¯·ç”Ÿæˆ {num_topics} ä¸ªå…·ä½“çš„ã€é«˜éš¾åº¦çš„ç»†åˆ†ä»»åŠ¡ã€‚
            è¦æ±‚ï¼šè¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ï¼ŒåŒ…å« 'topics' åˆ—è¡¨ã€‚
            
            JSON ç¤ºä¾‹ï¼š
            {{ "topics": ["ä»»åŠ¡A", "ä»»åŠ¡B", "ä»»åŠ¡C"] }}
            """
            
            raw_resp = client.generate(system_prompt, user_prompt)
            
            try:
                cleaned_resp = clean_json_text(raw_resp)
                data = json.loads(cleaned_resp)
                st.session_state.topics = data.get("topics", [])
                st.success(f"æˆåŠŸç”Ÿæˆ {len(st.session_state.topics)} ä¸ªä»»åŠ¡ä¸»é¢˜ï¼")
            except Exception as e:
                st.error(f"è§£æå¤±è´¥: {e}")
                st.text(raw_resp)

# æ˜¾ç¤ºå·²ç”Ÿæˆçš„ä¸»é¢˜
if st.session_state.topics:
    st.info(f"å½“å‰å¾…ç”Ÿæˆä¸»é¢˜ï¼š{', '.join(st.session_state.topics)}")

    st.divider()

    # åŒºåŸŸ 2: æ•°æ®ç”Ÿæˆ
    st.subheader("2. æ‰¹é‡ç”Ÿäº§é«˜è´¨é‡æ•°æ®")
    
    samples_per_topic = st.slider("æ¯ä¸ªä¸»é¢˜ç”Ÿæˆçš„æ•°æ®é‡", 1, 20, 3)
    
    if st.button("ğŸ”¥ å¼€å§‹è’¸é¦æ•°æ®"):
        client = LLMClient(provider, api_key, base_url, model_name)
        # ä¼ é€’Pollinations AIçš„é«˜çº§å‚æ•°
        if provider == "PollinationsAI":
            client.seed = pollinations_seed if pollinations_seed > 0 else None
            client.private = pollinations_private
        
        st.session_state.generated_data = [] # æ¸…ç©ºæ—§æ•°æ®
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_steps = len(st.session_state.topics)
        
        for i, topic in enumerate(st.session_state.topics):
            status_text.text(f"æ­£åœ¨ç”Ÿæˆä¸»é¢˜ ({i+1}/{total_steps}): {topic} ...")
            
            system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºé«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†çš„AIã€‚
            ä¸¥æ ¼è¦æ±‚ï¼š
            1. Outputå¿…é¡»åŒ…å« "Thought" (æ€ç»´é“¾) å’Œ "Answer"ã€‚
            2. æ ¼å¼å¿…é¡»æ˜¯åˆæ³•çš„ JSON åˆ—è¡¨ã€‚
            """
            
            user_prompt = f"""
            ä¸»é¢˜ï¼š{topic}
            è¯·ç”Ÿæˆ {samples_per_topic} æ¡å¤æ‚çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®ã€‚
            
            è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
            {{
                "samples": [
                    {{
                        "instruction": "ç”¨æˆ·æŒ‡ä»¤...",
                        "input": "ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰...",
                        "output": "Thought: ... Answer: ..."
                    }}
                ]
            }}
            """
            
            raw_resp = client.generate(system_prompt, user_prompt)
            
            try:
                cleaned_resp = clean_json_text(raw_resp)
                batch_data = json.loads(cleaned_resp).get("samples", [])
                
                for item in batch_data:
                    item['category'] = topic # æ·»åŠ å…ƒæ•°æ®
                    st.session_state.generated_data.append(item)
                    
            except Exception as e:
                st.warning(f"ä¸»é¢˜ {topic} ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((i + 1) / total_steps)
            time.sleep(0.5) # é¿å…é€Ÿç‡é™åˆ¶

        status_text.text("âœ… æ‰€æœ‰æ•°æ®ç”Ÿæˆå®Œæ¯•ï¼")
        
    # åŒºåŸŸ 3: ç»“æœå±•ç¤ºä¸ä¸‹è½½
    if st.session_state.generated_data:
        st.subheader("3. æ•°æ®é›†é¢„è§ˆä¸å¯¼å‡º")
        
        df = pd.DataFrame(st.session_state.generated_data)
        st.dataframe(df, use_container_width=True)
        
        # è½¬æ¢ä¸º JSONL æ ¼å¼ä¾›ä¸‹è½½
        jsonl_data = df.to_json(orient="records", lines=True, force_ascii=False)
        
        st.download_button(
            label="ğŸ’¾ ä¸‹è½½ JSONL æ ¼å¼æ•°æ®é›† (å¯ç›´æ¥ç”¨äºè®­ç»ƒ)",
            data=jsonl_data,
            file_name=f"dataset_{target_domain}.jsonl",
            mime="application/json"
        )
        
        # CSV ä¸‹è½½é€‰é¡¹
        csv_data = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ğŸ’¾ ä¸‹è½½ CSV æ ¼å¼ (ExcelæŸ¥çœ‹)",
            data=csv_data,
            file_name=f"dataset_{target_domain}.csv",
            mime="text/csv"
        )

# åŒºåŸŸ 4: Pollinations AI å›¾åƒç”Ÿæˆ (å·²ç§»é™¤)
# st.divider()
# st.subheader("4. ğŸ¨ AI å›¾åƒç”Ÿæˆ (Pollinations AI)")
# 
# # åˆå§‹åŒ–å›¾åƒç”ŸæˆçŠ¶æ€
# if "generated_images" not in st.session_state:
#     st.session_state.generated_images = []
#
# ... (å®Œæ•´å›¾åƒç”ŸæˆåŠŸèƒ½ä»£ç å·²æ³¨é‡Šç§»é™¤)
